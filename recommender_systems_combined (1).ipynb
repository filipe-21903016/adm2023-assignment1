{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d12d3b94-0237-4d10-a8e4-8300262078f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb565d6",
   "metadata": {},
   "source": [
    "Recommender systems are critical in providing personalized proposals for users across various fields. In this assignment, we aim to evaluate the performance of three algorithms covered in the course, namely Naive methods, UV matrix decomposition, and matrix factorization, and to provide insights into their effectiveness using the MovieLens 1M data set. Additionally, we used 5-fold cross-validation to increase the reliability of our recommender systems' results for data (movie or user) that did not occur in the training process. After implementing each of the algorithms, we used the Root Mean Squared Error (RMSE) and the Mean Absolute Error (MAE) over both the training and the test set for the examination of their accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95755b3d",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dde23472-3077-4e20-8f80-bb10e31a4ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chardet\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.lines as mlines\n",
    "import math\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c231150-0ce3-419a-8f86-a9a1f9cc5be0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a0dd82-388f-47e8-a9e3-34a76496e7e0",
   "metadata": {},
   "source": [
    "It appears that there is inconsistency in the text encoding used in various data files. As a result, we must verify the encoding to ensure accurate data reading from these files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cd895ea-9558-4625-b348-753c6276ed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_encoding(file_path):\n",
    "    \"\"\"\n",
    "    This function checks the text enconding used in a particular file\n",
    "    \n",
    "    :param file_path: The file path you wish to examine for its encoding\n",
    "    :return: String containing enconding type\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(file_path, 'rb') as f:\n",
    "        result = chardet.detect(f.read())\n",
    "        return result['encoding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf48e43c-ed09-4306-b8fd-acaf23c9bf34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  Timestamp\n",
       "0       1     1193       5  978300760\n",
       "1       1      661       3  978302109\n",
       "2       1      914       3  978301968\n",
       "3       1     3408       4  978300275\n",
       "4       1     2355       5  978824291"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading ratings data\n",
    "ratings_path =\"./ratings.dat\"\n",
    "ratings = pd.read_csv(ratings_path, delimiter=\"::\", header=None, engine='python', encoding=get_file_encoding(ratings_path))\n",
    "ratings = ratings.rename(columns={0: \"UserID\", 1: \"MovieID\", 2: \"Rating\", 3:\"Timestamp\"}) # Set ratings column names\n",
    "\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "961137de-33e8-4406-8382-557f1917216b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MovieID                               Title                        Genres\n",
       "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4        5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading movies data\n",
    "movies_path = \"./movies.dat\"\n",
    "movies = pd.read_csv(movies_path, delimiter=\"::\", header=None, engine='python', encoding= get_file_encoding(movies_path))\n",
    "movies = movies.rename(columns={0: \"MovieID\", 1: \"Title\", 2: \"Genres\"})\n",
    "\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4760af66-ca6c-4ff8-af76-292c7d6ab212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Zip-code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID Gender  Age  Occupation Zip-code\n",
       "0       1      F    1          10    48067\n",
       "1       2      M   56          16    70072\n",
       "2       3      M   25          15    55117\n",
       "3       4      M   45           7    02460\n",
       "4       5      M   25          20    55455"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading users data\n",
    "users_path = \"./users.dat\"\n",
    "users = pd.read_csv(users_path, delimiter=\"::\", header=None, engine='python', encoding= get_file_encoding(users_path))\n",
    "users = users.rename(columns={0: \"UserID\", 1: \"Gender\", 2: \"Age\", 3: \"Occupation\", 4: \"Zip-code\"})\n",
    "\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d18dcb",
   "metadata": {},
   "source": [
    "#### Missing values check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80edab15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(ratings.isna().sum().sum())\n",
    "print(movies.isna().sum().sum())\n",
    "print(users.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffd0ef9",
   "metadata": {},
   "source": [
    "# Naive Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176476de",
   "metadata": {},
   "source": [
    "To begin with the first recommender systems algorithm, we implement four functions for each naive recommender approach, namely the Global Average, the Movie Average, the User Average, and the Linear combination (including the $\\gamma$ parameter). The first one, the Global Average approach, involves recommending the global average rating to all users. When movie or user average ratings were unavailable for the Movie Average or User Average approach, this approach was utilized as a fallback value. Proceeding to these approaches, recommendations were based on the average rating received by a movie or given by a user, respectively. Finally, the last approach we implemented was the Linear combination of the three averages. In this approach, predictions are a combination of user and movie average ratings, with the $\\gamma$ term included. In that case, we used the Movie and User Average Ratings in the Linear Combination function. Thus, the fall-back value used for these approaches was used indirectly for the fourth one when user or movie average ratings were unavailable. Hence, in the last approach, the global average rating was implicitly used again as the fall-back value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b663c3e",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb5a5a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30005d8f",
   "metadata": {},
   "source": [
    "#### 1. Global Average Rating:\n",
    "\n",
    "$$ {R}_{global} (User, Movie) = mean(\\text{all ratings})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "559be5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_average(train, test, is_train=False):\n",
    "    if is_train:\n",
    "        return [train['Rating'].mean()] * len(train)\n",
    "    else:\n",
    "        return [train['Rating'].mean()] * len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6567c852",
   "metadata": {},
   "source": [
    "#### 2. Movie Average: \n",
    "\n",
    "$$ {R}_{movie} (User, Movie) = mean(\\text{all ratings for movie})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0054cc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_average(train, test, is_train=False):\n",
    "    if is_train:\n",
    "        movie_avg_train = train.groupby('MovieID')['Rating'].mean()\n",
    "        return movie_avg_train[train['MovieID']].to_numpy()    # A NumPy ndarray representing the values in this Series\n",
    "\n",
    "    else:\n",
    "        movie_avg_predictions = test['MovieID'].map(train.groupby('MovieID')['Rating'].mean())  # movie average predictions for a test set based on \n",
    "        movie_avg_predictions.fillna(train['Rating'].mean(), inplace=True)                       # the movie average ratings in the training set             \n",
    "        return movie_avg_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dcfbb6",
   "metadata": {},
   "source": [
    "#### 3. User Average:\n",
    "\n",
    "$$ {R}_{user} (User, Movie) = mean(\\text{all ratings for User})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93ae54e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_average(train, test, is_train=False):\n",
    "    if is_train:\n",
    "        user_avg_train = train.groupby('UserID')['Rating'].mean()\n",
    "        return user_avg_train[train['UserID']].to_numpy()    # A NumPy ndarray representing the values in this Series\n",
    "\n",
    "    else:\n",
    "        user_avg_predictions = test['UserID'].map(train.groupby('UserID')['Rating'].mean()) # user average predictions for a test set based on \n",
    "        user_avg_predictions.fillna(train['Rating'].mean(), inplace=True)                       # the user average ratings in the training set\n",
    "        return user_avg_predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ae6277",
   "metadata": {},
   "source": [
    "#### 4. Linear Combination of the three averages:\n",
    "\n",
    "$$ {R}_{user-movie} (User, Movie) = \\alpha * {R}_{user} (User, Movie) + \\beta * {R}_{movie} (User, Movie) + \\gamma$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95ad6708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_combination(train, test, is_train=False):\n",
    "    user_avg = train.groupby('UserID')['Rating'].mean()\n",
    "    movie_avg = train.groupby('MovieID')['Rating'].mean()\n",
    "\n",
    "    A = np.vstack([user_avg[train['UserID']], movie_avg[train['MovieID']], np.ones(len(train))]).T\n",
    "    b = train['Rating']\n",
    "\n",
    "    alpha, beta, gamma = np.linalg.lstsq(A, b, rcond=None)[0]     # https://numpy.org/doc/stable/reference/generated/numpy.linalg.lstsq.html\n",
    "\n",
    "    if is_train: \n",
    "        prediction = alpha * user_average(train, test, is_train=True) + beta * movie_average(train, test, is_train=True) + gamma\n",
    "    else:\n",
    "        prediction = alpha * user_average(train, test) + beta * movie_average(train, test) + gamma\n",
    "\n",
    "    prediction = np.clip(prediction, 1, 5)\n",
    "\n",
    "    return prediction\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e35e6d",
   "metadata": {},
   "source": [
    "## 5-fold Cross-Validation \\& Accuracy estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53736f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)   # 42: random seed set at the beginning\n",
    "\n",
    "# training set\n",
    "rmse_global_train = []\n",
    "mae_global_train = []\n",
    "\n",
    "rmse_user_train = []\n",
    "mae_user_train = []\n",
    "\n",
    "rmse_movie_train = []\n",
    "mae_movie_train = []\n",
    "\n",
    "rmse_combination_train = []\n",
    "mae_combination_train = []\n",
    "\n",
    "# test set\n",
    "rmse_global_test = []\n",
    "mae_global_test = []\n",
    "\n",
    "rmse_user_test = []\n",
    "mae_user_test = []\n",
    "\n",
    "rmse_movie_test = []\n",
    "mae_movie_test = []\n",
    "\n",
    "rmse_combination_test = []\n",
    "mae_combination_test = []\n",
    "\n",
    "for train_index, test_index in kf.split(ratings):\n",
    "    train_data, test_data = ratings.iloc[train_index], ratings.iloc[test_index]\n",
    "\n",
    "    # Compute RMSE and MAE over training set\n",
    "    rmse_global_train.append(np.sqrt(mean_squared_error(train_data['Rating'], global_average(train_data, test_data, is_train=True))))\n",
    "    mae_global_train.append(mean_absolute_error(train_data['Rating'], global_average(train_data, test_data, is_train=True)))\n",
    "\n",
    "    rmse_user_train.append(np.sqrt(mean_squared_error(train_data['Rating'], user_average(train_data, test_data, is_train=True))))\n",
    "    mae_user_train.append(mean_absolute_error(train_data['Rating'], user_average(train_data, test_data, is_train=True)))\n",
    "\n",
    "    rmse_movie_train.append(np.sqrt(mean_squared_error(train_data['Rating'], movie_average(train_data, test_data, is_train=True))))\n",
    "    mae_movie_train.append(mean_absolute_error(train_data['Rating'], movie_average(train_data, test_data, is_train=True)))\n",
    "\n",
    "    rmse_combination_train.append(np.sqrt(mean_squared_error(train_data['Rating'], linear_combination(train_data, test_data, is_train=True))))\n",
    "    mae_combination_train.append(mean_absolute_error(train_data['Rating'], linear_combination(train_data, test_data, is_train=True)))\n",
    "\n",
    "    # Compute RMSE and MAE test set\n",
    "    rmse_global_test.append(np.sqrt(mean_squared_error(test_data['Rating'], global_average(train_data, test_data))))\n",
    "    mae_global_test.append(mean_absolute_error(test_data['Rating'], global_average(train_data, test_data)))\n",
    "\n",
    "    rmse_user_test.append(np.sqrt(mean_squared_error(test_data['Rating'], user_average(train_data, test_data))))\n",
    "    mae_user_test.append(mean_absolute_error(test_data['Rating'], user_average(train_data, test_data)))\n",
    "\n",
    "    rmse_movie_test.append(np.sqrt(mean_squared_error(test_data['Rating'], movie_average(train_data, test_data))))\n",
    "    mae_movie_test.append(mean_absolute_error(test_data['Rating'], movie_average(train_data, test_data)))\n",
    "\n",
    "    rmse_combination_test.append(np.sqrt(mean_squared_error(test_data['Rating'], linear_combination(train_data, test_data))))\n",
    "    mae_combination_test.append(mean_absolute_error(test_data['Rating'], linear_combination(train_data, test_data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad525546",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = {\"Metric\": [\"RMSE\", \"MAE\"],\n",
    "          \"Global Average\": [np.mean(rmse_global_train).round(3), np.mean(mae_global_train).round(3)],\n",
    "          \"User Average\": [np.mean(rmse_user_train).round(3), np.mean(mae_user_train).round(3)],\n",
    "          \"Movie Average\": [np.mean(rmse_movie_train).round(3), np.mean(mae_movie_train).round(3)],\n",
    "          \"Linear Combination\": [np.mean(rmse_combination_train).round(3),np.mean(mae_combination_train).round(3)]}\n",
    "df_train = pd.DataFrame(data=d_train)\n",
    "\n",
    "d_test = {\"Metric\": [\"RMSE\", \"MAE\"],\n",
    "          \"Global Average\": [np.mean(rmse_global_test).round(3), np.mean(mae_global_test).round(3)],\n",
    "          \"User Average\": [np.mean(rmse_user_test).round(3), np.mean(mae_user_test).round(3)],\n",
    "          \"Movie Average\": [np.mean(rmse_movie_test).round(3), np.mean(mae_movie_test).round(3)],\n",
    "          \"Linear Combination\": [np.mean(rmse_combination_test).round(3),np.mean(mae_combination_test).round(3)]}\n",
    "df_test = pd.DataFrame(data=d_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d71f9cd",
   "metadata": {},
   "source": [
    "#### RMSE and MAE table over training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c03066fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Global Average</th>\n",
       "      <th>User Average</th>\n",
       "      <th>Movie Average</th>\n",
       "      <th>Linear Combination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>1.117</td>\n",
       "      <td>1.028</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAE</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Metric  Global Average  User Average  Movie Average  Linear Combination\n",
       "0   RMSE           1.117         1.028          0.974               0.915\n",
       "1    MAE           0.934         0.823          0.778               0.725"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb74ec58",
   "metadata": {},
   "source": [
    "#### RMSE and MAE table over test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c379921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Global Average</th>\n",
       "      <th>User Average</th>\n",
       "      <th>Movie Average</th>\n",
       "      <th>Linear Combination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>1.117</td>\n",
       "      <td>1.035</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAE</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Metric  Global Average  User Average  Movie Average  Linear Combination\n",
       "0   RMSE           1.117         1.035          0.979               0.924\n",
       "1    MAE           0.934         0.829          0.782               0.732"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91093190",
   "metadata": {},
   "source": [
    "#### Discussion on RMSE - MAE tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572603c9",
   "metadata": {},
   "source": [
    "We compute the RMSE and MAE over both the training and test sets to assess how well the model performs during training (learning) and when applied to unknown data (testing). Consequently, in both sets, the Linear Combination approach is the most accurate naïve method, implying that considering both user and movie average ratings, with the parameter $\\gamma$ in the linear regression model, leads to better recommendations. On the contrary, the Global Average approach is less accurate but still provides valid and straightforward recommendations, making it an acceptable starting point. As for the User Average and Movie Average, their RMSE and MAE values fall in between the Global Average and Linear Combination, indicating that personalized recommendations based on user or movie averages can be reasonably accurate.\n",
    "Overall, the differences in RMSE and MAE values among the four approaches are relatively small, indicating that these naive approaches provide competitive in accuracy results for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203072b5",
   "metadata": {},
   "source": [
    "# UV Matrix Decomposition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024980b1-e568-49ee-9bd5-ac058dcef16c",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba274610",
   "metadata": {},
   "source": [
    "### k-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67c18919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsme(y_true, y_pred):\n",
    "    return math.sqrt(np.square(np.subtract(y_true, y_pred)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4cf19e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_true, y_pred):\n",
    "    return np.absolute(np.subtract(y_true, y_pred)).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6846aa11-f4f6-43ef-8da6-947399d46d21",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Rating for item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "966ed013-14e0-4c55-ab09-a4ca85c741e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_global = ratings['Rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2359b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_item(item, ratings):\n",
    "    \"\"\"\n",
    "    Calculate the average rating for a specific movie item.\n",
    "\n",
    "    :param item: The unique identifier (MovieID) for the movie.\n",
    "    :type item: int\n",
    "\n",
    "    :return: The average rating for the specified movie item if ratings are available,\n",
    "             or the global rating if there are no ratings for the given movie.\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    ratings_item = ratings[(ratings['MovieID'] == item)]\n",
    "    return ratings_item['Rating'].mean() if len(ratings_item) > 0 else r_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31f8e06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average rates of all items\n",
    "R_i = {}\n",
    "\n",
    "for movieID in ratings['MovieID'].unique():\n",
    "    R_i[movieID] = r_item(movieID, ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf228b6-220a-4f41-96ed-575e90b70ab6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Rating for user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d2c7fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_user(user, ratings):\n",
    "    \"\"\"\n",
    "    Calculate the average rating given by a specific user.\n",
    "\n",
    "    :param user: The unique identifier (UserID) for the user.\n",
    "    :type user: int\n",
    "\n",
    "    :return: The average rating given by the specified user if ratings are available,\n",
    "             or the global rating if there are no ratings provided by the user.\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    ratings_user = ratings[(ratings['UserID'] == user)]\n",
    "    return ratings_user['Rating'].mean() if len(ratings_user) > 0 else r_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "223e4ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average rates of all users\n",
    "R_u = {}\n",
    "\n",
    "for userID in ratings['UserID'].unique():\n",
    "    R_u[userID] = r_user(userID, ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ababca7e-6eb0-4052-b3bd-3c61e1b6779f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### RoundRobin Implementation for matrix optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b1e53ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class roundrobin:\n",
    "    \"\"\"\n",
    "    A custom iterator for interleaving two arrays in a round-robin fashion.\n",
    "\n",
    "    :param U: The first array to be interleaved.\n",
    "    :type U: numpy.ndarray\n",
    "\n",
    "    :param V: The second array to be interleaved.\n",
    "    :type V: numpy.ndarray\n",
    "\n",
    "    This class is used to create a custom iterator that interleaves elements from two arrays 'U' and 'V' in a\n",
    "    round-robin fashion.\n",
    "    \"\"\"\n",
    "    def __init__(self, U, V):\n",
    "        self.U = U\n",
    "        self.V = V\n",
    "        \n",
    "        self.maxrows1, self.maxcols1 = U.shape[0], U.shape[1]\n",
    "        self.maxrows2, self.maxcols2 = V.shape[0], V.shape[1]\n",
    "        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.iterU = True\n",
    "        self.row1 = self.col1 = 0\n",
    "        self.row2 = self.col2 = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.iterU:\n",
    "            if self.row1 > self.maxrows1 - 1:\n",
    "                self.row1 = 0\n",
    "                self.col1 += 1\n",
    "                if self.col1 > self.maxcols1 - 1:\n",
    "                    raise StopIteration\n",
    "\n",
    "            next_ = (self.iterU, self.row1, self.col1)\n",
    "            self.iterU = False\n",
    "            self.row1 += 1\n",
    "            return next_\n",
    "        else:    \n",
    "            if self.row2 > self.maxrows2 - 1:\n",
    "                self.row2 = 0\n",
    "                self.col2 += 1\n",
    "                if self.col2 > self.maxcols2 - 1:\n",
    "                    raise StopIteration\n",
    "\n",
    "            next_ = (self.iterU, self.row2, self.col2)\n",
    "            self.iterU = True\n",
    "            self.row2 += 1\n",
    "            return next_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5b6e64-153f-46d7-aa7f-caaab2a8f0e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### UV-Decomposition Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6fa83db3-20d9-43c2-898c-6481045a02e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UVDecomposition:\n",
    "    def __init__(self, X):\n",
    "        self.X = X\n",
    "    \n",
    "    # Define loss function\n",
    "    def rmse_2d(self, M, M_pred):\n",
    "        mask = ~np.isnan(M)\n",
    "        return math.sqrt(np.mean(np.square(M - M_pred), where=~np.isnan(M)))\n",
    "    \n",
    "    def optimize_x(self, M, U, V, r, s):\n",
    "        \"\"\"\n",
    "        Optimize U[r, s] in UV decomposition.\n",
    "        \"\"\"\n",
    "        urk = np.delete(U[r, :], s, axis=0)\n",
    "        vkj = np.delete(V, s, axis=0)\n",
    "\n",
    "        vsj = V[s, :]\n",
    "\n",
    "        numerator = vsj * (M[r, :] - np.dot(urk.reshape(-1,1).T, vkj))\n",
    "        numerator = np.sum(numerator, where=~np.isnan(numerator))\n",
    "\n",
    "        denominator = np.square(vsj)\n",
    "        denominator = np.sum(denominator)\n",
    "\n",
    "        return numerator / denominator\n",
    "    \n",
    "    def optimize_y(self, M, U, V, r, s):\n",
    "        \"\"\"\n",
    "        Optimize V[r, s] in UV decomposition.\n",
    "        \"\"\"\n",
    "        uik = np.delete(U, r, axis=1)\n",
    "        vks = np.delete(V[:,s], r, axis=0)\n",
    "\n",
    "        uir = U[:,r]\n",
    "\n",
    "        numerator = uir * (M[:,s] - np.dot(uik, vks))\n",
    "        numerator = np.sum(numerator, where=~np.isnan(numerator))\n",
    "\n",
    "        denominator = np.square(uir)\n",
    "        denominator = np.sum(denominator, where=~np.isnan(denominator))\n",
    "\n",
    "        return numerator / denominator\n",
    "    \n",
    "    def fit(self):\n",
    "        # n Users\n",
    "        unique_users = self.X['UserID'].unique()\n",
    "        n = len(unique_users)\n",
    "\n",
    "        # m Items\n",
    "        unique_items = self.X['MovieID'].unique()\n",
    "        m = len(unique_items)\n",
    "\n",
    "        # Initialize utility matrix\n",
    "        M = np.full((n,m), np.nan)\n",
    "        \n",
    "        # Map ids to index & vice-versa\n",
    "        self.user_to_index = {user_id: idx for idx, user_id in enumerate(unique_users)}\n",
    "        self.index_to_user = {idx: user_id for idx, user_id in enumerate(unique_users)}\n",
    "        self.item_to_index = {item_id: idx for idx, item_id in enumerate(unique_items)}\n",
    "        self.index_to_item = {idx: item_id for idx, item_id in enumerate(unique_items)}\n",
    "        \n",
    "        # Populate matrix M\n",
    "        for _, row in self.X.iterrows():\n",
    "            user_id = row['UserID']\n",
    "            item_id = row['MovieID']\n",
    "            rating = row['Rating']\n",
    "\n",
    "            norm = (R_u[user_id] + R_i[item_id]) / 2\n",
    "            M[self.user_to_index[user_id], self.item_to_index[item_id]] = rating - norm\n",
    "            \n",
    "        \n",
    "        # Mean of non-blank values in M\n",
    "        d = 10\n",
    "        self.U = np.random.uniform(-0.5, 0.5, (n,d))\n",
    "        self.V = np.random.uniform(-0.5, 0.5, (d,m))\n",
    "        \n",
    "        same_err = 0\n",
    "        last_err = float('inf')\n",
    "        for epoch in range(15):\n",
    "            # Stop if error doesn't improve for 3 epochs\n",
    "            if same_err >= 3:\n",
    "              break\n",
    "\n",
    "            # Training\n",
    "            for isU, r, s in roundrobin(self.U, self.V):\n",
    "                if isU:\n",
    "                    self.U[r,s] = self.optimize_x(M, self.U, self.V, r, s)\n",
    "                else:\n",
    "                    self.V[r,s] = self.optimize_y(M, self.U, self.V, r, s)\n",
    "\n",
    "            # Monitoring\n",
    "            UV = np.dot(self.U, self.V)\n",
    "            err = round(self.rmse_2d(M, UV), 3)\n",
    "            print(f'Epoch {epoch} | RMSE: {err}')\n",
    "            if err == last_err:\n",
    "              same_err += 1\n",
    "            last_err = err\n",
    "        \n",
    "    # def predict(self, X_test):\n",
    "    #     \"\"\"\n",
    "    #     Predict ratings for test data using matrix decomposition.\n",
    "\n",
    "    #     :param X_test: Test data containing user and item pairs for prediction.\n",
    "    #     :type X_test: pandas.DataFrame\n",
    "\n",
    "    #     :return: A list of predicted ratings for the test data.\n",
    "    #     :rtype: list\n",
    "\n",
    "    #     For each row in the test data, it calculates the normalization value 'norm' because the values in the UV matrix are normalized, and\n",
    "    #     we need to reverse this normalization to obtain the actual predicted ratings.\n",
    "    #     \"\"\"\n",
    "    #     UV = np.dot(self.U, self.V)\n",
    "    #     y_pred = []\n",
    "    #     for _, x in X_test.iterrows():\n",
    "    #         user_id = x['UserID']\n",
    "    #         item_id = x['MovieID']\n",
    "    #         norm = (R_u[user_id] + R_i[item_id]) / 2\n",
    "    #         y_pred.append(UV[self.user_to_index[user_id], self.item_to_index[item_id]] + norm)\n",
    "            # return y_pred\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        Predict ratings for test data using matrix decomposition.\n",
    "        \"\"\"\n",
    "        UV = np.dot(self.U, self.V)\n",
    "        y_pred = []\n",
    "        for _, x in X_test.iterrows():\n",
    "            user_id = x['UserID']\n",
    "            item_id = x['MovieID']\n",
    "            # Check if user_id and item_id exist in dictionaries\n",
    "            if user_id in self.user_to_index and item_id in self.item_to_index:\n",
    "                norm = (R_u[user_id] + R_i[item_id]) / 2\n",
    "                y_pred.append(UV[self.user_to_index[user_id], self.item_to_index[item_id]] + norm)\n",
    "            else:\n",
    "                # Handle case where user_id or item_id is not found\n",
    "                y_pred.append(np.mean(np.mean(UV)))  # Set an appropriate default value or handle the case accordingly\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2702ae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(X, k = 5):   \n",
    "    \"\"\"\n",
    "    Perform k-fold cross-validation to evaluate a model's performance.\n",
    "\n",
    "    :param model: The machine learning model to be evaluated.\n",
    "    :type model: Any machine learning model supporting `fit` and `predict` methods.\n",
    "\n",
    "    :param X: The feature data used for training and testing the model.\n",
    "    :type X: pandas.DataFrame\n",
    "\n",
    "    :param y: The target values for training and testing the model.\n",
    "    :type y: pandas.Series\n",
    "\n",
    "    :param k: The number of folds in the cross-validation (default is 5).\n",
    "    :type k: int\n",
    "\n",
    "    :return: A tuple containing the average root mean squared error (RMSE) for both training\n",
    "             and test sets, and the average mean absolute error (MAE) for both training and test sets.\n",
    "    :rtype: tuple of tuples, e.g., ((rmse_train_aver, rmse_test_aver), (mae_train_aver, mae_test_aver))\n",
    "\n",
    "    This function performs k-fold cross-validation by splitting the data into training and test sets, training the\n",
    "    model on the training sets, and evaluating it on both training and test sets for each fold. It calculates RMSE\n",
    "    and MAE for each fold and returns the averages across all folds.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Shuffle data\n",
    "    X = shuffle(X, random_state=42)\n",
    "    \n",
    "    # Split data\n",
    "    n = len(X)\n",
    "    X_folds = [X.iloc[(i - 1) * (n // k):i * (n // k),:] for i in range(1, k + 1)]\n",
    "    \n",
    "    # Initialize array to store RSME calculations\n",
    "    rmse_ = np.empty((0, 2), float)\n",
    "    mae_ = np.empty((0, 2), float)\n",
    "    \n",
    "    \n",
    "    for i, X_test in enumerate(X_folds):\n",
    "        X_train = pd.concat([X for j, X in enumerate(X_folds) if i != j])\n",
    "        \n",
    "        # Train model\n",
    "        model = UVDecomposition(X_train)\n",
    "        model.fit()\n",
    "\n",
    "        # Evaluate on training and test set\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        \n",
    "        y_train = X_train['Rating']\n",
    "        y_test = X_test['Rating']\n",
    "\n",
    "        # Calculate errors\n",
    "        rmse_train = rsme(y_train, y_train_pred) \n",
    "        rmse_test = rsme(y_test, y_test_pred)\n",
    "        mae_train = mae(y_train, y_train_pred)\n",
    "        mae_test = mae(y_test, y_test_pred)\n",
    "        \n",
    "        rmse_ = np.append(rmse_, np.array([[rmse_train, rmse_test]]), axis = 0)\n",
    "        mae_ = np.append(mae_, np.array([[mae_train, mae_test]]), axis = 0)\n",
    "    \n",
    "    rmse_train_aver = rmse_[:, 0].mean()\n",
    "    rmse_test_aver = rmse_[:, 1].mean()\n",
    "    mae_train_aver = mae_[:, 0].mean()\n",
    "    mae_test_aver = mae_[:, 1].mean()\n",
    "    \n",
    "    return (rmse_train_aver, rmse_test_aver), (mae_train_aver, mae_test_aver)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4689247c-24d2-48f4-be20-a2877af1d323",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30dc8924-8842-43e0-b763-4ed83c20f34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | RMSE: 0.949\n",
      "Epoch 1 | RMSE: 0.922\n",
      "Epoch 2 | RMSE: 0.905\n",
      "Epoch 3 | RMSE: 0.903\n",
      "Epoch 4 | RMSE: 0.901\n",
      "Epoch 5 | RMSE: 0.901\n",
      "Epoch 6 | RMSE: 0.9\n",
      "Epoch 7 | RMSE: 0.9\n",
      "Epoch 8 | RMSE: 0.899\n",
      "Epoch 9 | RMSE: 0.899\n",
      "Epoch 0 | RMSE: 0.95\n",
      "Epoch 1 | RMSE: 0.912\n",
      "Epoch 2 | RMSE: 0.905\n",
      "Epoch 3 | RMSE: 0.903\n",
      "Epoch 4 | RMSE: 0.902\n",
      "Epoch 5 | RMSE: 0.901\n",
      "Epoch 6 | RMSE: 0.901\n",
      "Epoch 7 | RMSE: 0.901\n",
      "Epoch 8 | RMSE: 0.901\n",
      "Epoch 0 | RMSE: 0.95\n",
      "Epoch 1 | RMSE: 0.915\n",
      "Epoch 2 | RMSE: 0.904\n",
      "Epoch 3 | RMSE: 0.903\n",
      "Epoch 4 | RMSE: 0.902\n",
      "Epoch 5 | RMSE: 0.901\n",
      "Epoch 6 | RMSE: 0.9\n",
      "Epoch 7 | RMSE: 0.9\n",
      "Epoch 8 | RMSE: 0.9\n",
      "Epoch 9 | RMSE: 0.9\n",
      "Epoch 0 | RMSE: 0.949\n",
      "Epoch 1 | RMSE: 0.916\n",
      "Epoch 2 | RMSE: 0.903\n",
      "Epoch 3 | RMSE: 0.903\n",
      "Epoch 4 | RMSE: 0.902\n",
      "Epoch 5 | RMSE: 0.901\n",
      "Epoch 6 | RMSE: 0.901\n",
      "Epoch 7 | RMSE: 0.9\n",
      "Epoch 8 | RMSE: 0.9\n",
      "Epoch 0 | RMSE: 0.949\n",
      "Epoch 1 | RMSE: 0.919\n",
      "Epoch 2 | RMSE: 0.906\n",
      "Epoch 3 | RMSE: 0.903\n",
      "Epoch 4 | RMSE: 0.902\n",
      "Epoch 5 | RMSE: 0.901\n",
      "Epoch 6 | RMSE: 0.901\n",
      "Epoch 7 | RMSE: 0.9\n",
      "Epoch 8 | RMSE: 0.9\n",
      "Epoch 9 | RMSE: 0.9\n",
      "RMSE Train: 0.9\n",
      "MAE Train: 0.717\n",
      "RMSE Test: 0.911\n",
      "MAE Test: 0.726\n"
     ]
    }
   ],
   "source": [
    "(rmse_training, rmse_test) , (mae_training, mae_test) = cross_validation(ratings)\n",
    "\n",
    "print(f'RMSE Train: {round(rmse_training, 3)}\\nMAE Train: {round(mae_training, 3)}')\n",
    "print(f'RMSE Test: {round(rmse_test, 3)}\\nMAE Test: {round(mae_test, 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314d0b90-8068-4386-9ecc-aa218b16fbca",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "The table below displays the achieved results in comparison to the most effective approach among the naive methods.\n",
    "\n",
    "|               | Linear Combination | UV Decomposition |\n",
    "|:-------------:|:------------------:|:----------------:|\n",
    "| RMSE Training |        0.915       |       0.9      |\n",
    "|  MAE Training |        0.725       |       0.717      |\n",
    "|   RMSE Test   |        0.924       |       0.911      |\n",
    "|    MAE Test   |        0.732       |       0.726     |\n",
    "\n",
    "We can see that the UV Decomposition decrease both RMSE and MAE error both in training sets and the test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6285fe",
   "metadata": {},
   "source": [
    "# Matrix Factorization with Gradient Descent and Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507f8201",
   "metadata": {},
   "source": [
    "For this part of the report, matrix factorization algorithm is going to be implemented in a similar way with the one described in the gravity-Tikk.pdf paper. To be more specific, this algorithm takes as an input a Ratings Matrix, where each row i represents users, each column j represents movies and the (i,j) element of the matrix is the rating of user i to the movie j. However, this matrix has many elements that are zeros, since not all users have rated all the movies.  So, the algorithm aims to predict the zero elements of the matrix by filling the whole Ratings matrix. To achieve that, it decompose the Ratings matrix into the product of two matrices U (for users) and M (for movies). The U matrix has as many rows as the users and K columns, whereas the M matrix has as many columns as the movies are and K rows. The value of K is going to be chosen, based on the smaller achieved test root mean squares error(RMSE) and mean absolute error(MAE), after some experiments are conducted. The goal of the algorithm is to minimize the difference between the predicted ratings matrix and the real one ratings matrix, taking into account, while calculating that difference, only the (i,j) elements of the matrices that were not initialy zero in the real ratings matrix. The problem is solved using a gradient method to adjust elements of U and M in each iteration, so that to minimize the error between the real rating and the predicted rating. Additionally, regularization is applied to prevent overfitting. The first thing that the algorithm does is to initialize the  U and M matrices randomly and then choose learning rate (η), regularization factor (λ), K and max number of iterations. Then, it iteratively updates U and M untill the RMSE on the probe subset(list of [i,j,rating] elements, where the rating is not 0 on the real ratings matrix) stop decreasing for two consecutive iterations or untill the max number of iterations chosen. In addition to the gravity-Tikk.pdf paper, the gradients here are penalized to not exceed the value of 1 and the predicted ratings matrix is squeezed to [1,5], meaning that values less than 1 are changed to be 1 and values greater than 5, are changed to be 5. Also, if the RMSE does not reduce for two consecutive iterations but it is not lower than 1, the algorithm continues untill it reaches the maximum number of iterations.\n",
    "\n",
    "Since this algorithm takes hours to run, the experiments are run using the parameters that are reported on the MyMedialite website: num_factors=10, num_iter=75, regilarization=0/05, learnr_rate=0.05.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917a68bc",
   "metadata": {},
   "source": [
    "Before implementing the algorthim though, some preprocessing of the data should be done. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0c563e",
   "metadata": {},
   "source": [
    "## Pre-processing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c8e86c",
   "metadata": {},
   "source": [
    "The users and movies dataframes are encoded in order to have continues userID and movieID values without any gaps. Their indexes are also reset to be continuous. That is because we want each row of the Ratings matrix to be able to be mapped with the respective userID and each column of the Ratings matrix to be able to be mapped with the respective row of the movieID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120547f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "unique_users_ids = ratings.loc[:,'UserID'].unique().copy()\n",
    "# Assuming your movies features matrix is named 'movies_features_df'\n",
    "filtered_users = users[users.loc[:,'UserID'].isin(unique_users_ids)].copy()\n",
    "\n",
    "unique_movies_ids = ratings.loc[:,'MovieID'].unique().copy()\n",
    "# Assuming your movies features matrix is named 'movies_features_df'\n",
    "filtered_movies = movies[movies.loc[:,'MovieID'].isin(unique_movies_ids)].copy()\n",
    "\n",
    "\n",
    "filtered_movies.loc[:, 'MovieID'] = le.fit_transform(filtered_movies['MovieID']).copy()\n",
    "filtered_users.loc[:, 'UserID'] = le.fit_transform(filtered_users['UserID']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae9aa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_movies.reset_index(drop=True, inplace=True)\n",
    "filtered_users.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f733636",
   "metadata": {},
   "source": [
    "Finally the Ratings matrix is created as a dataframe and named as 'user_movie_retings'. Each row represents a UserID and each column a MovieID. In this matrix all the users ratings are presented. The zeros in the matrix represent movies that the specific user have not rated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f921fa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_movie_ratings = ratings.pivot(index='UserID', columns='MovieID', values='Rating').fillna(0)\n",
    "\n",
    "# Encode columns (MovieIDs)\n",
    "user_movie_ratings.columns = le.fit_transform(user_movie_ratings.columns)\n",
    "\n",
    "# Encode row names (UserIDs)\n",
    "user_movie_ratings.index = le.fit_transform(user_movie_ratings.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de2d23b",
   "metadata": {},
   "source": [
    "## Implementing the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86ba15b",
   "metadata": {},
   "source": [
    "\n",
    "Here a class named MatrixFactorization is created to implement the aformentioned algorithm. It is initialized with the values of K, max iterations, η and λ. Then, the algorthm is performed in the .fit instance, using operations on matrices in order to avoid nested loops which are slow. U and M are initialized using the random library. The class has also instances to return the predicted ratings matrix, the mae and rmse of the train set and the rmse and mae on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b0b2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization:\n",
    "    def __init__(self, K=10, max_iter=75, eta=0.005, lamda=0.05):\n",
    "        self.K = K  # Features of matrices\n",
    "        self.max_iter = max_iter  # Maximum number of iterations\n",
    "        self.eta = eta  # Learning rate\n",
    "        self.lamda = lamda  # Regularization parameter\n",
    "\n",
    "    def fit(self, train_set):\n",
    "        self.zero_rows=np.where(~train_set.values.any(axis=1))[0] #\n",
    "        self.zero_columns=np.where(~train_set.values.any(axis=0))[0]\n",
    "\n",
    "        prev_rmse = float('inf')\n",
    "        consecutive_increase_count = 0\n",
    "\n",
    "        probe_subset = [(i, j, train_set.iloc[i, j]) for i in range(len(train_set)) for j in range(len(train_set.columns)) if train_set.iloc[i, j] > 0]\n",
    "\n",
    "        N, Z = train_set.shape  # Dimensions of the user-item matrix\n",
    "        self.train_set_values=train_set.values\n",
    "\n",
    "        self.U = np.random.rand(N, self.K)  # Initialize user matrix randomly\n",
    "        self.M = np.random.rand(Z, self.K)  # Initialize movie matrix randomly\n",
    "\n",
    "        raw_predictions = np.dot(self.U, self.M.T)\n",
    "        self.predictions =  np.clip(raw_predictions, 1, 5)\n",
    "\n",
    "        plot_rmse_train=[]\n",
    "        plot_rmse_test=[]\n",
    "        for step in range(self.max_iter):\n",
    "            # Calculate errors for non-zero entries in train_set\n",
    "            train_values = np.where(np.isnan(train_set.values), 0, train_set.values) #put zero where there is nan\n",
    "            U_values = np.where(np.isnan(self.U), 0, self.U)\n",
    "            M_T_values = np.where(np.isnan(self.M.T), 0, self.M.T)\n",
    "\n",
    "            errors = (train_values > 0) * (train_values - np.dot(U_values, M_T_values)) #erors in all positions of array without zeros in train\n",
    "\n",
    "\n",
    "            # Calculate gradients for U and M using matrix operations\n",
    "            gradient_U = 2 * (np.dot(errors, self.M) - self.lamda * self.U)\n",
    "            gradient_M = 2 * (np.dot(errors.T, self.U) - self.lamda * self.M)\n",
    "\n",
    "\n",
    "            max_gradient = 1.0  # Set an appropriate maximum gradient value\n",
    "            gradient_U = np.clip(gradient_U, -max_gradient, max_gradient)\n",
    "            gradient_M = np.clip(gradient_M, -max_gradient, max_gradient)\n",
    "\n",
    "            self.U += self.eta * gradient_U\n",
    "            self.M += self.eta * gradient_M\n",
    "\n",
    "            raw_predictions = np.dot(self.U, self.M.T)\n",
    "            self.predictions =  np.clip(raw_predictions, 1, 5)\n",
    "\n",
    "            # Calculate RMSE on the probe subset\n",
    "            train_probe_rmse = self.get_rmse(probe_subset)\n",
    "            train_probe_mae = self.get_mae(probe_subset)\n",
    "\n",
    "\n",
    "            print(\"Iteration:\", step + 1, \" train RMSE:\", train_probe_rmse, \"train MAE:\", train_probe_mae)\n",
    "\n",
    "            plot_rmse_train.append(train_probe_rmse)\n",
    "\n",
    "            # Check for convergence by comparing RMSE with the previous iteration\n",
    "            if train_probe_rmse >= prev_rmse:\n",
    "                consecutive_increase_count += 1\n",
    "                if consecutive_increase_count >= 2 and train_probe_rmse<=1:\n",
    "                    print(\"Converged. RMSE did not decrease for 2 consecutive iterations.\")\n",
    "                    print('Train RMSE:',train_probe_rmse)\n",
    "                    print('Train MAE:',train_probe_mae)\n",
    "                    break\n",
    "            else:\n",
    "                consecutive_increase_count = 0\n",
    "\n",
    "            prev_rmse = train_probe_rmse\n",
    "\n",
    "\n",
    "        raw_predictions = np.dot(self.U, self.M.T)\n",
    "        self.predictions =  np.clip(raw_predictions, 1, 5)\n",
    "\n",
    "\n",
    "        return train_probe_rmse,train_probe_mae, plot_rmse_train\n",
    "\n",
    "    def predict(self):\n",
    "        return self.predictions\n",
    "\n",
    "\n",
    "    def test_rmse_mae(self, test_data):\n",
    "        test_data = test_data.values\n",
    "        nR = self.predictions\n",
    "\n",
    "        non_zero_mask = (test_data > 0) & np.logical_not(np.isin(np.arange(len(test_data)), self.zero_rows)[:, np.newaxis]) & np.logical_not(np.isin(np.arange(len(test_data[0])), self.zero_columns))\n",
    "        actual_ratings = test_data[non_zero_mask]\n",
    "        predicted_ratings = nR[non_zero_mask]\n",
    "\n",
    "        rmse = np.sqrt(np.mean((predicted_ratings - actual_ratings) ** 2))\n",
    "        mae = np.mean(np.abs(predicted_ratings - actual_ratings))\n",
    "\n",
    "        return rmse, mae\n",
    "\n",
    "\n",
    "    def get_rmse(self, probe_subset):\n",
    "        rmse = 0\n",
    "        count = 0\n",
    "        for i, j, actual_rating in probe_subset:\n",
    "            predicted_rating = self.predictions [i,j]\n",
    "            rmse += (predicted_rating - actual_rating) ** 2\n",
    "            count += 1\n",
    "        rmse = np.sqrt(rmse / count)\n",
    "        return rmse\n",
    "\n",
    "    def get_mae(self, probe_subset):\n",
    "        mae = 0\n",
    "        count = 0\n",
    "        for i, j, actual_rating in probe_subset:\n",
    "            predicted_rating = self.predictions [i,j]\n",
    "            mae += np.abs(predicted_rating - actual_rating)\n",
    "            count += 1\n",
    "        mae = mae / count\n",
    "        return mae\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6160e072",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afbeb11",
   "metadata": {},
   "source": [
    "\n",
    "For the results to be more accurate 5-fold cross validation is performed using a function named cross_validation. This function takes as input the model, which is from the MatrixFactorization class, the dataphrame with the real ratings and the number of folds that the dataphrame is going to be split into. To split the data into 4 train sets and 1 test set, a list of tubles is created with (user,movie, rating) elements, for the elements of the matrix that are non zero. Then the train matrix, which has the same shape as the original matrix is filled with the 4/5 of those data and the test matrix, which also has the same shape as the original matrix is filled with the 1/5 of those data. This happens for 5 times in order to have different combinations of train and test sets. If a user or a movie is not presented in the train matrix (i.e all elements of a specific row (user) are filled with zeros or all elements of a specific column (movie) are filled with zeros), then that user and that movie are not taking into account when calculation the RMSE and MAE on the test data. In the cross validation function, the fit instance of the model is called for every one of the five times that the spliting is performed and for each time the test RMSE and MAE are calculated and printed. At the end, the avairage of those values is also printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112bab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model, data_df, num_folds=5):\n",
    "\n",
    "\n",
    "    num_users, num_movies = data_df.shape\n",
    "\n",
    "    # Create a list of (user, movie, rating) tuples from the DataFrame\n",
    "    data = [(user, movie, data_df.iloc[user, movie]) for user in range(num_users) for movie in range(num_movies) if data_df.iloc[user, movie] != 0]\n",
    "\n",
    "\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Initialize empty DataFrames for train and test sets\n",
    "    train_sets = [pd.DataFrame(np.zeros((num_users, num_movies))) for _ in range(num_folds)]\n",
    "    test_sets = [pd.DataFrame(np.zeros((num_users, num_movies))) for _ in range(num_folds)]\n",
    "\n",
    "    # Iterate through the folds\n",
    "    train_sum_rmse = 0\n",
    "    train_sum_mae = 0\n",
    "\n",
    "    test_sum_rmse = 0\n",
    "    test_sum_mae = 0\n",
    "\n",
    "    plot_train=[]\n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(data), 1):\n",
    "        train_data = [data[i] for i in train_index]\n",
    "        test_data = [data[i] for i in test_index]\n",
    "\n",
    "        # Fill train and test DataFrames with ratings from the respective data tuples\n",
    "        for user, movie, rating in train_data:\n",
    "            train_sets[fold - 1].iloc[user, movie] = rating\n",
    "\n",
    "        for user, movie, rating in test_data:\n",
    "            test_sets[fold - 1].iloc[user, movie] = rating\n",
    "\n",
    "        mf = model\n",
    "        (train_rmse,train_mae, plot_train_rmse) = mf.fit(train_sets[fold - 1])\n",
    "\n",
    "        plot_train.append(plot_train_rmse)\n",
    "\n",
    "        (test_rmse,test_mae) =mf.test_rmse_mae(test_sets[fold - 1])\n",
    "\n",
    "        print('Final train RMSE for fold:',fold,':', train_rmse)\n",
    "        print('Final train MAE for fold:',fold,':', train_mae)\n",
    "\n",
    "        print('Final test RMSE for fold:',fold,':', test_rmse)\n",
    "        print('Final test MAE for fold:',fold,':', test_mae)\n",
    "\n",
    "        train_sum_rmse = train_sum_rmse + train_rmse\n",
    "        train_sum_mae = train_sum_mae + train_mae\n",
    "\n",
    "\n",
    "        test_sum_rmse = test_sum_rmse + test_rmse\n",
    "        test_sum_mae = test_sum_mae + test_mae\n",
    "\n",
    "    overall_train_rmse=train_sum_rmse/num_folds\n",
    "    overall_train_mae=train_sum_mae/num_folds\n",
    "\n",
    "    overall_test_rmse=test_sum_rmse/num_folds\n",
    "    overall_test_mae=test_sum_mae/num_folds\n",
    "\n",
    "    print('Overall Train RMSE:',overall_train_rmse)\n",
    "    print('Overall Train MAE:',overall_train_mae)\n",
    "\n",
    "    print('Overall Test RMSE:',overall_test_rmse)\n",
    "    print('Overall Test MAE:',overall_test_mae)\n",
    "\n",
    "    return plot_train,  overall_test_rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dfb0c7",
   "metadata": {},
   "source": [
    "## Run experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712c3bd4",
   "metadata": {},
   "source": [
    "Time to run the experiments. The cross validation function is called 3 times, each time with a different value of K in order to compare their performance. The values that are tried are K=10,15,20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3a71a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df=user_movie_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b975cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=MatrixFactorization()\n",
    "(plot1_train,plot1_test)=cross_validation(model1, data_df, num_folds=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71464d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=MatrixFactorization(K=15)\n",
    "(plot2_train,plot2_test)=cross_validation(model2, data_df, num_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eed7523",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3=MatrixFactorization(K=20)\n",
    "(plot3_train,plot3_test)=cross_validation(model3, data_df, num_folds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085e2262",
   "metadata": {},
   "source": [
    "For the three Ks that the algorithm was run, a plot with the training RMSE curve for all the folds is ploted, against the iterations. On the same plot, the straight line represents the final overall test RMSE for the specific K. So, for K=10 the results are: \n",
    "\n",
    "Overall Train RMSE: 0.8839608355048773\n",
    "Overall Train MAE: 0.6994310596144893\n",
    "Overall Test RMSE: 0.9253240684611157\n",
    "Overall Test MAE: 0.7316915551664489\n",
    "\n",
    "This means that the predicted ratings do not deviate much from the real ratings and the algortihm can be used to predict the rate that a user would give to a movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa40a427",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train=[plot1_train,plot2_train,plot3_train] #list of lists of rmses for each fold\n",
    "plot_test=[plot1_test,plot2_test,plot3_test] #list of three numbers to create strainght lines\n",
    "\n",
    "Ks = [10,15,20]\n",
    "plt.rcParams['font.size'] = '16'\n",
    "figure, axis = plt.subplots(1,3, figsize=(45,10))\n",
    "max_rmse = max(max([max(max(train_fold), plot_test) for train_fold in plot_train]))\n",
    "\n",
    "for i in range(3):\n",
    "  for j in range(len(plot_train[i])):\n",
    "      axis[i].plot(range(1, len(plot_train[i][j]) + 1), plot_train[i][j], linestyle=\"-\", color='blue', label=f'Fold {i + 1} Train')\n",
    "      y=[plot_test[i]]*len(plot_train[i][j])\n",
    "      axis[i].plot(range(1, len(plot_train[i][j]) + 1), y, linestyle=\"-\", color='red', label=f'Fold {i + 1} Test')\n",
    "\n",
    "      axis[i].set_title('Dimension:'+ str(Ks[i]))\n",
    "      axis[i].set_ylabel('RMSE')\n",
    "      axis[i].set_xlabel('iterations')\n",
    "\n",
    "      axis[i].set_ylim(0, max_rmse)\n",
    "\n",
    "train_legend = mlines.Line2D([], [], color='blue', label='Train RMSE')\n",
    "test_legend = mlines.Line2D([], [], color='red', label='Test RMSE')\n",
    "\n",
    "# Adding legends to each subplot\n",
    "axis[0].legend(handles=[train_legend, test_legend])\n",
    "axis[1].legend(handles=[train_legend, test_legend])\n",
    "axis[2].legend(handles=[train_legend, test_legend])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f88185",
   "metadata": {},
   "source": [
    "The lines are very similar and all the models performed rather well. The K with the best performance though, is the one with K=10 as it achieved the smallest overall RMSE and MAE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76bb25b",
   "metadata": {},
   "source": [
    "## Output for Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8700922e",
   "metadata": {},
   "source": [
    "Perform the Matrix Factorization on all the dataset, with the best chosen K=10 and print the U and M matrices for users and movies respectively to be used for the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a75acc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v=MatrixFactorization()\n",
    "model_v.fit(data_df)\n",
    "U = model_v.U\n",
    "M = model_v.M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75979f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('users_mf.csv', U, delimiter=',')\n",
    "np.savetxt('movies_mf.csv', M, delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc-autonumbering": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
